#!/usr/bin/env python3
"""
å¾®ä¿¡å…¬ä¼—å·æ–‡ç« æ‰¹é‡å¯¼å‡ºè„šæœ¬

ä½¿ç”¨æ–¹å¼ï¼š
1. å…ˆåœ¨æµè§ˆå™¨è®¿é—® http://localhost:3001 æ‰«ç ç™»å½•
2. è¿è¡Œæ­¤è„šæœ¬è·å–æ–‡ç« 
"""

import os
import json
import asyncio
import aiohttp
import urllib.parse
from datetime import datetime, date
from pathlib import Path
from dataclasses import dataclass
from typing import List, Optional, Dict, Any

# é…ç½®
BASE_URL = "http://localhost:3001"
DATA_DIR = Path("/Users/angeloxu/Desktop/finradar/fin_module/wechat-article/data")
OUTPUT_DIR = Path("/Users/angeloxu/Desktop/finradar/fin_module/wechat-article/exports")


@dataclass
class Article:
    """æ–‡ç« æ•°æ®"""
    aid: str
    title: str
    link: str
    digest: str
    author: str
    cover: str
    create_time: datetime
    
    def __str__(self):
        return f"[{self.create_time.strftime('%Y-%m-%d %H:%M')}] {self.title}"


def get_auth_key() -> Optional[str]:
    """ä» KV å­˜å‚¨ä¸­è·å– auth-key"""
    kv_dir = DATA_DIR / "kv" / "cookie"
    if not kv_dir.exists():
        return None
    
    # è·å–ç¬¬ä¸€ä¸ª auth-key æ–‡ä»¶
    for f in kv_dir.iterdir():
        if f.is_file():
            return f.name
    return None


async def search_account(session: aiohttp.ClientSession, 
                         keyword: str, 
                         auth_key: str) -> List[Dict]:
    """æœç´¢å…¬ä¼—å·"""
    url = f"{BASE_URL}/api/web/mp/searchbiz"
    params = {"keyword": keyword}
    headers = {"X-Auth-Key": auth_key}
    
    async with session.get(url, params=params, headers=headers) as resp:
        if resp.status != 200:
            print(f"âŒ æœç´¢å¤±è´¥: HTTP {resp.status}")
            return []
        
        data = await resp.json()
        if data.get("base_resp", {}).get("ret") != 0:
            print(f"âŒ æœç´¢å¤±è´¥: {data.get('base_resp', {}).get('err_msg')}")
            return []
        
        return data.get("list", [])


async def get_articles(session: aiohttp.ClientSession,
                       fakeid: str,
                       auth_key: str,
                       begin: int = 0,
                       size: int = 20) -> List[Article]:
    """è·å–å…¬ä¼—å·æ–‡ç« åˆ—è¡¨"""
    url = f"{BASE_URL}/api/web/mp/appmsgpublish"
    params = {
        "id": fakeid,
        "keyword": "",
        "begin": begin,
        "size": size
    }
    headers = {"X-Auth-Key": auth_key}
    
    async with session.get(url, params=params, headers=headers) as resp:
        if resp.status != 200:
            print(f"âŒ è·å–æ–‡ç« å¤±è´¥: HTTP {resp.status}")
            return []
        
        data = await resp.json()
        if data.get("base_resp", {}).get("ret") != 0:
            print(f"âŒ è·å–æ–‡ç« å¤±è´¥: {data.get('base_resp', {}).get('err_msg')}")
            return []
        
        articles = []
        
        # publish_page æ˜¯ä¸€ä¸ª JSON å­—ç¬¦ä¸²ï¼Œéœ€è¦å†è§£æä¸€æ¬¡
        publish_page_str = data.get("publish_page", "{}")
        if isinstance(publish_page_str, str):
            publish_page = json.loads(publish_page_str)
        else:
            publish_page = publish_page_str
        
        publish_list = publish_page.get("publish_list", [])
        
        for item in publish_list:
            try:
                publish_info = json.loads(item.get("publish_info", "{}"))
                appmsgex_list = publish_info.get("appmsgex", [])
                
                for appmsg in appmsgex_list:
                    create_time = datetime.fromtimestamp(appmsg.get("create_time", 0))
                    
                    article = Article(
                        aid=appmsg.get("aid", ""),
                        title=appmsg.get("title", ""),
                        link=appmsg.get("link", "").replace("\\/", "/"),
                        digest=appmsg.get("digest", ""),
                        author=appmsg.get("author_name", ""),
                        cover=appmsg.get("cover", "").replace("\\/", "/"),
                        create_time=create_time
                    )
                    articles.append(article)
            except Exception as e:
                print(f"âš ï¸ è§£ææ–‡ç« æ•°æ®å¤±è´¥: {e}")
                continue
        
        return articles


async def download_article_html(session: aiohttp.ClientSession,
                                 article: Article,
                                 output_dir: Path) -> bool:
    """ä¸‹è½½æ–‡ç«  HTML å†…å®¹"""
    try:
        # ç›´æ¥è®¿é—®å¾®ä¿¡æ–‡ç« é“¾æ¥
        async with session.get(article.link, timeout=30) as resp:
            if resp.status != 200:
                print(f"âŒ ä¸‹è½½å¤±è´¥ [{article.title[:20]}...]: HTTP {resp.status}")
                return False
            
            html_content = await resp.text()
            
            # ä¿å­˜æ–‡ä»¶
            safe_title = "".join(c for c in article.title if c.isalnum() or c in ' _-')[:50]
            filename = f"{article.create_time.strftime('%Y%m%d_%H%M')}_{safe_title}.html"
            filepath = output_dir / filename
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            print(f"âœ… å·²ä¿å­˜: {filename}")
            return True
            
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¼‚å¸¸ [{article.title[:20]}...]: {e}")
        return False


async def export_articles_to_json(articles: List[Article], 
                                   account_name: str,
                                   output_dir: Path) -> str:
    """å¯¼å‡ºæ–‡ç« åˆ—è¡¨ä¸º JSON"""
    output_dir.mkdir(parents=True, exist_ok=True)
    
    data = {
        "account": account_name,
        "export_time": datetime.now().isoformat(),
        "count": len(articles),
        "articles": [
            {
                "aid": a.aid,
                "title": a.title,
                "link": a.link,
                "digest": a.digest,
                "author": a.author,
                "cover": a.cover,
                "create_time": a.create_time.isoformat()
            }
            for a in articles
        ]
    }
    
    filename = f"{account_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    filepath = output_dir / filename
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    return str(filepath)


async def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ“± å¾®ä¿¡å…¬ä¼—å·æ–‡ç« æ‰¹é‡å¯¼å‡º")
    print("=" * 60)
    
    # è·å– auth-key
    auth_key = get_auth_key()
    if not auth_key:
        print("âŒ æœªæ‰¾åˆ°ç™»å½•å‡­è¯ï¼è¯·å…ˆåœ¨æµè§ˆå™¨è®¿é—® http://localhost:3001 æ‰«ç ç™»å½•")
        return
    
    print(f"âœ… å·²è·å–ç™»å½•å‡­è¯: {auth_key[:8]}...")
    
    # è¦æœç´¢çš„å…¬ä¼—å·
    target_account = "æ–°æ™ºå…ƒ"
    
    async with aiohttp.ClientSession() as session:
        # 1. æœç´¢å…¬ä¼—å·
        print(f"\nğŸ” æœç´¢å…¬ä¼—å·: {target_account}")
        accounts = await search_account(session, target_account, auth_key)
        
        if not accounts:
            print("âŒ æœªæ‰¾åˆ°å…¬ä¼—å·")
            return
        
        # æ˜¾ç¤ºæœç´¢ç»“æœ
        print(f"ğŸ“‹ æ‰¾åˆ° {len(accounts)} ä¸ªå…¬ä¼—å·:")
        for i, acc in enumerate(accounts[:5]):
            print(f"   [{i+1}] {acc.get('nickname')} (@{acc.get('alias', 'N/A')})")
        
        # é€‰æ‹©ç¬¬ä¸€ä¸ªï¼ˆé€šå¸¸æ˜¯æœ€åŒ¹é…çš„ï¼‰
        selected = accounts[0]
        fakeid = selected.get("fakeid")
        account_name = selected.get("nickname")
        
        print(f"\nğŸ“Œ é€‰æ‹©: {account_name}")
        
        # 2. è·å–æ–‡ç« åˆ—è¡¨
        print(f"\nğŸ“° è·å–æ–‡ç« åˆ—è¡¨...")
        articles = await get_articles(session, fakeid, auth_key, begin=0, size=20)
        
        if not articles:
            print("âŒ æœªè·å–åˆ°æ–‡ç« ")
            return
        
        print(f"ğŸ“Š å…±è·å– {len(articles)} ç¯‡æ–‡ç« ")
        
        # 3. ç­›é€‰ä»Šå¤©çš„æ–‡ç« 
        today = date.today()
        today_articles = [a for a in articles if a.create_time.date() == today]
        
        print(f"\nğŸ“… ä»Šæ—¥ ({today}) æ–‡ç« : {len(today_articles)} ç¯‡")
        
        if today_articles:
            for i, article in enumerate(today_articles, 1):
                print(f"   [{i}] {article}")
            
            # 4. å¯¼å‡ºä¸º JSON
            OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
            json_path = await export_articles_to_json(today_articles, account_name, OUTPUT_DIR)
            print(f"\nğŸ’¾ å·²å¯¼å‡º JSON: {json_path}")
            
            # æ˜¾ç¤ºæ–‡ç« é“¾æ¥
            print(f"\nğŸ”— æ–‡ç« é“¾æ¥:")
            for article in today_articles:
                print(f"   â€¢ {article.title}")
                print(f"     {article.link}")
                print()
        else:
            print("â„¹ï¸ ä»Šå¤©æš‚æ— æ–°æ–‡ç« ")
            print("\nğŸ“‹ æœ€è¿‘æ–‡ç« :")
            for article in articles[:5]:
                print(f"   â€¢ [{article.create_time.strftime('%Y-%m-%d')}] {article.title}")
    
    print("\n" + "=" * 60)
    print("âœ… å¯¼å‡ºå®Œæˆ!")
    print("=" * 60)


if __name__ == "__main__":
    asyncio.run(main())
